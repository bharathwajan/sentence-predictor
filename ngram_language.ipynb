{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reuters \n",
    "The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into two sets, called \"training\" and \"test\"; thus, the text with fileid 'test/14826' is a document drawn from the test set. This split is for training and testing algorithms that automatically detect the topic of a document, as we will see in chap-data-intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "# len(reuters.fileids())\n",
    "# reuters.fileids() #gets each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.StreamBackedCorpusView"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reuters.words('test/14826'))\n",
    "\n",
    "# string_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating no. of grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk import ngrams\n",
    "from funcy import flatten, isa\n",
    "\n",
    "unigram=defaultdict(int)\n",
    "bigram=defaultdict(int)\n",
    "trigram=defaultdict(int)\n",
    "fourgram=defaultdict(int)\n",
    "fivegram=defaultdict(int)\n",
    "\n",
    "def gram_calc(sentence,gram):\n",
    "    if gram==1:\n",
    "        temp=list(ngrams(sentence,gram))\n",
    "        for gram in temp:\n",
    "            unigram[gram]+=1\n",
    "        return unigram\n",
    "    elif gram==2:\n",
    "        temp=list(ngrams(sentence,gram))\n",
    "        for gram in temp:\n",
    "            bigram[gram]+=1\n",
    "        return bigram\n",
    "    elif gram==3:\n",
    "        temp=list(ngrams(sentence,gram))\n",
    "        for gram in temp:\n",
    "            trigram[gram]+=1\n",
    "        return trigram\n",
    "    elif gram==4:\n",
    "        temp=list(ngrams(sentence,gram))\n",
    "        for gram in temp:\n",
    "            fourgram[gram]+=1\n",
    "        return fourgram\n",
    "    elif gram==5:\n",
    "        temp=list(ngrams(sentence,gram))\n",
    "        for gram in temp:\n",
    "            fivegram[gram]+=1\n",
    "        return fivegram\n",
    "\n",
    "def start_stop_adder(news):\n",
    "    sentence=[]\n",
    "    temp=[]\n",
    "    for word in news:\n",
    "        # print(word)\n",
    "        if word!=\".\":\n",
    "            temp.append(word)\n",
    "        elif word==\" \":\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                temp[0]=\"<s>\"\n",
    "                temp[len(temp)-1]=\"</s>\"\n",
    "            except IndexError:\n",
    "                pass\n",
    "            sentence.append([\" \".join(temp)])\n",
    "            temp=[]\n",
    "    return sentence\n",
    "\n",
    "for news in reuters.fileids():\n",
    "    lowered_news = [each_string.lower() for each_string in reuters.words(news)]\n",
    "    sentences=start_stop_adder(lowered_news)\n",
    "    para=[]\n",
    "    for sentence in sentences:\n",
    "        para.append(sentence[0].split(\" \"))\n",
    "    para = list(flatten(para))\n",
    "    gram_calc(para,1)\n",
    "    gram_calc(para,2)\n",
    "    gram_calc(para,3)\n",
    "    gram_calc(para,4)\n",
    "    gram_calc(para,5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1569202\n",
      "1559452\n",
      "1549702\n",
      "1539961\n",
      "1530223\n"
     ]
    }
   ],
   "source": [
    "uni_count=0\n",
    "for key,value in unigram.items():\n",
    "    uni_count+=value\n",
    "print(uni_count)\n",
    "\n",
    "bi_count=0\n",
    "for key,value in bigram.items():\n",
    "    bi_count+=value\n",
    "print(bi_count)\n",
    "\n",
    "tri_count=0\n",
    "for key,value in trigram.items():\n",
    "    tri_count+=value\n",
    "print(tri_count)\n",
    "\n",
    "four_count=0\n",
    "for key,value in fourgram.items():\n",
    "    four_count+=value\n",
    "print(four_count)\n",
    "\n",
    "five_count=0\n",
    "for key,value in fivegram.items():\n",
    "    five_count+=value\n",
    "print(five_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conditional probability : <br>\n",
    "Bigram   : p(b|a)=p(a∩b)/p(a)<br>\n",
    "trigram  : P(A| B,C) =P(A∩B∩C) /P(B∩C)<br>\n",
    "fourgram : P(A| B,C,D) =P(A∩B∩C∩D) /P(B∩C∩D)<br>\n",
    "fivegram : P(A| B,C,D,E) =P(A∩B∩C∩D∩E) /P(B∩C∩D∩E)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprob=defaultdict(int)\n",
    "for key, value in unigram.items():\n",
    "    new_value = value/uni_count\n",
    "    uniprob[key] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "biprob=defaultdict(int)\n",
    "for key, value in bigram.items():\n",
    "    temp=[]\n",
    "    temp.append(f'{key[1]}')\n",
    "    temp=tuple(temp)\n",
    "    prob_val=value/unigram[temp]\n",
    "    biprob[key]=prob_val \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "triprob=defaultdict(int)\n",
    "for key, value in trigram.items():\n",
    "    temp=key[1:3]\n",
    "    prob_val=value/bigram[temp]\n",
    "    triprob[key]=prob_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourprob=defaultdict(int)\n",
    "for key,value in fourgram.items():\n",
    "    temp=key[1:4]\n",
    "    prob_val=value/trigram[temp]\n",
    "    fourprob[key]=prob_val\n",
    "# four_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveprob=defaultdict(int)\n",
    "for key,value in fivegram.items():\n",
    "    temp=key[1:5]\n",
    "    prob_val=value/fourgram[temp]\n",
    "    fiveprob[key]=prob_val\n",
    "# four_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using markov's assumption on chain rule of probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction\n",
    "n = how many words has to be predicted<br>\n",
    "grams=how many grams does user wants us to predict the next word<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporters fear tighter monetary gamesmanship\n",
      "exporters fear damage from frigid temperatures expected tonight\n",
      "japan has raised fears among many\n",
      "raised fears among many of asia ' s exporting nations that\n"
     ]
    }
   ],
   "source": [
    "def predict(ip,n,grams):\n",
    "    ip=ip.split(\" \")\n",
    "    if grams==2:\n",
    "        for i in range(n):\n",
    "            # print(ip)\n",
    "            temp=[0]\n",
    "            predictor=0.0\n",
    "            for key,value in biprob.items():\n",
    "                try:\n",
    "                    if key[0]==ip[-1]:\n",
    "                        if biprob[key]>predictor:\n",
    "                            predictor=biprob[key]\n",
    "                            temp[0]=(key,value)\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            # print(temp)\n",
    "            # print(ip)\n",
    "            ip.append(temp[0][0][-1])\n",
    "        # print(ip)\n",
    "        # print(temp)\n",
    "        return \" \".join(ip)\n",
    "    if grams==3:\n",
    "        for i in range(n):\n",
    "            # print(ip)\n",
    "            temp=[0]\n",
    "            predictor=0.0\n",
    "            for key,value in triprob.items():\n",
    "                try:\n",
    "                    if key[0:2]==tuple(ip[-2:]):\n",
    "                        # print(\"here\",key[0:2],ip[-2:])\n",
    "                        if triprob[key]>predictor:\n",
    "                            predictor=triprob[key]\n",
    "                            temp[0]=(key,value)\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            # print(\"temp\",temp)\n",
    "            # print(temp[0][0][-1])\n",
    "            # print(ip)\n",
    "            # break\n",
    "            # print([0][0])\n",
    "            ip.append(temp[0][0][-1])\n",
    "        # print(\"after append ip\",ip)\n",
    "        # print(\"temp\",temp)\n",
    "        return \" \".join(ip)\n",
    "    if grams==4:\n",
    "        for i in range(n):\n",
    "            # print(ip)\n",
    "            temp=[0]\n",
    "            predictor=0.0\n",
    "            for key,value in fourprob.items():\n",
    "                try:\n",
    "                    if key[0:3]==tuple(ip[-3:]):\n",
    "                        # print(\"here\",key[0:2],ip[-2:])\n",
    "                        if fourprob[key]>predictor:\n",
    "                            predictor=fourprob[key]\n",
    "                            temp[0]=(key,value)\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            # print(\"temp\",temp)\n",
    "            # print(temp[0][0][-1])\n",
    "            # print(ip)\n",
    "            # break\n",
    "            # print([0][0])\n",
    "            ip.append(temp[0][0][-1])\n",
    "        # print(\"after append ip\",ip)\n",
    "        # print(\"temp\",temp)\n",
    "        return \" \".join(ip)\n",
    "    if grams==5:\n",
    "        for i in range(n):\n",
    "            # print(ip)\n",
    "            temp=[0]\n",
    "            predictor=0.0\n",
    "            for key,value in fiveprob.items():\n",
    "                try:\n",
    "                    if key[0:4]==tuple(ip[-4:]):\n",
    "                        # print(\"here\",key[0:2],ip[-2:])\n",
    "                        if fiveprob[key]>predictor:\n",
    "                            predictor=fiveprob[key]\n",
    "                            temp[0]=(key,value)\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            # print(\"temp\",temp)\n",
    "            # print(temp[0][0][-1])\n",
    "            # print(ip)\n",
    "            # break\n",
    "            # print([0][0])\n",
    "            ip.append(temp[0][0][-1])\n",
    "        # print(\"after append ip\",ip)\n",
    "        # print(\"temp\",temp)\n",
    "        return \" \".join(ip)\n",
    " \n",
    " \n",
    " \n",
    "print(predict(\"exporters fear\",3,2)) #predicting the next two words using bigram\n",
    "print(predict(\"exporters fear damage\",5,3))#predicting the next five words using trigram\n",
    "print(predict(\"japan has raised fears\",2,4))#predicting the next five words using fourgram\n",
    "print(predict(\"raised fears among many of\",6,5))#predicting the next six words using fivegrams"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c58f1a80e29ce2a76e539ab98fc081c95233123a1a48f521102ec1d9072b477"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('machine_learning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
